{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf \n",
    "import os\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "from keras_preprocessing.image import load_img\n",
    "# from tensorflow.keras.preprocessing.image import load_img\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainDir = r\"images/train\" \n",
    "TestDir = r\"images/validation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDataFrame(Dir):\n",
    "  imgPaths = []\n",
    "  imgLabels = []\n",
    "  \n",
    "  for label in os.listdir(Dir):\n",
    "    for img in os.listdir(os.path.join(Dir,label)):\n",
    "      imgPaths.append(os.path.join(Dir,label,img))\n",
    "      imgLabels.append(label)\n",
    "    print(label, \"Completed\")\n",
    "  return imgPaths, imgLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angry Completed\n",
      "disgust Completed\n",
      "fear Completed\n",
      "happy Completed\n",
      "neutral Completed\n",
      "sad Completed\n",
      "surprise Completed\n",
      "\n",
      "angry Completed\n",
      "disgust Completed\n",
      "fear Completed\n",
      "happy Completed\n",
      "neutral Completed\n",
      "sad Completed\n",
      "surprise Completed\n"
     ]
    }
   ],
   "source": [
    "train = pd.DataFrame()\n",
    "test = pd.DataFrame()\n",
    "\n",
    "train['images'], train['labels'] = createDataFrame(TrainDir)\n",
    "print()\n",
    "test['images'], test['labels'] = createDataFrame(TestDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>images</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>images/train\\angry\\0.jpg</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>images/train\\angry\\1.jpg</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>images/train\\angry\\10.jpg</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>images/train\\angry\\10002.jpg</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>images/train\\angry\\10016.jpg</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28816</th>\n",
       "      <td>images/train\\surprise\\9969.jpg</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28817</th>\n",
       "      <td>images/train\\surprise\\9985.jpg</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28818</th>\n",
       "      <td>images/train\\surprise\\9990.jpg</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28819</th>\n",
       "      <td>images/train\\surprise\\9992.jpg</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28820</th>\n",
       "      <td>images/train\\surprise\\9996.jpg</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28821 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               images    labels\n",
       "0            images/train\\angry\\0.jpg     angry\n",
       "1            images/train\\angry\\1.jpg     angry\n",
       "2           images/train\\angry\\10.jpg     angry\n",
       "3        images/train\\angry\\10002.jpg     angry\n",
       "4        images/train\\angry\\10016.jpg     angry\n",
       "...                               ...       ...\n",
       "28816  images/train\\surprise\\9969.jpg  surprise\n",
       "28817  images/train\\surprise\\9985.jpg  surprise\n",
       "28818  images/train\\surprise\\9990.jpg  surprise\n",
       "28819  images/train\\surprise\\9992.jpg  surprise\n",
       "28820  images/train\\surprise\\9996.jpg  surprise\n",
       "\n",
       "[28821 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>images</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>images/validation\\angry\\10052.jpg</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>images/validation\\angry\\10065.jpg</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>images/validation\\angry\\10079.jpg</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>images/validation\\angry\\10095.jpg</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>images/validation\\angry\\10121.jpg</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7061</th>\n",
       "      <td>images/validation\\surprise\\9806.jpg</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7062</th>\n",
       "      <td>images/validation\\surprise\\9830.jpg</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7063</th>\n",
       "      <td>images/validation\\surprise\\9853.jpg</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7064</th>\n",
       "      <td>images/validation\\surprise\\9878.jpg</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7065</th>\n",
       "      <td>images/validation\\surprise\\993.jpg</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7066 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   images    labels\n",
       "0       images/validation\\angry\\10052.jpg     angry\n",
       "1       images/validation\\angry\\10065.jpg     angry\n",
       "2       images/validation\\angry\\10079.jpg     angry\n",
       "3       images/validation\\angry\\10095.jpg     angry\n",
       "4       images/validation\\angry\\10121.jpg     angry\n",
       "...                                   ...       ...\n",
       "7061  images/validation\\surprise\\9806.jpg  surprise\n",
       "7062  images/validation\\surprise\\9830.jpg  surprise\n",
       "7063  images/validation\\surprise\\9853.jpg  surprise\n",
       "7064  images/validation\\surprise\\9878.jpg  surprise\n",
       "7065   images/validation\\surprise\\993.jpg  surprise\n",
       "\n",
       "[7066 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureExtraction(images):\n",
    "    imgFeatures = []\n",
    "    \n",
    "    for image in tqdm(images):\n",
    "        img = load_img(image,color_mode='grayscale')\n",
    "        img = np.array(img)\n",
    "        imgFeatures.append(img)\n",
    "    imgFeatures = np.array(imgFeatures)\n",
    "    imgFeatures = imgFeatures.reshape(len(imgFeatures),48,48,1)\n",
    "    \n",
    "    return imgFeatures\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28821/28821 [01:23<00:00, 347.22it/s]\n"
     ]
    }
   ],
   "source": [
    "train_features = featureExtraction(train['images'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7066/7066 [00:31<00:00, 224.31it/s]\n"
     ]
    }
   ],
   "source": [
    "test_features = featureExtraction(test['images'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_features/255.0\n",
    "x_test = test_features/255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(train['labels'])\n",
    "\n",
    "y_train = le.transform(train['labels'])\n",
    "y_test = le.transform(test['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train,num_classes=7)\n",
    "y_test = to_categorical(y_test,num_classes=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "\n",
    "# model.add(Conv2D(128,kernel_size=(3,3), activation = 'relu', input_shape=(48,48,1)))\n",
    "# model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "# model.add(Dropout(0.4))\n",
    "\n",
    "# model.add(Conv2D(256,kernel_size=(3,3), activation = 'relu', input_shape=(48,48,1)))\n",
    "# model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "# model.add(Dropout(0.4))\n",
    "\n",
    "# model.add(Conv2D(512,kernel_size=(3,3), activation = 'relu', input_shape=(48,48,1)))\n",
    "# model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "# model.add(Dropout(0.4))\n",
    "\n",
    "# model.add(Conv2D(512,kernel_size=(3,3), activation = 'relu', input_shape=(48,48,1)))\n",
    "# model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "# model.add(Dropout(0.4))\n",
    "\n",
    "# model.add(Flatten())\n",
    "\n",
    "\n",
    "# model.add(Dense(512,activation='relu'))\n",
    "# model.add(Dropout(0.4))\n",
    "\n",
    "# model.add(Dense(256,activation='relu'))\n",
    "# model.add(Dropout(0.3))\n",
    "\n",
    "# model.add(Dense(7,activation = 'softmax'))\n",
    "\n",
    "\n",
    "# model.compile(optimizer='adam', loss='categorical_crossentropy', metrics='accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(x=x_train, y=y_train, batch_size=128, epochs=100, validation_data=(x_test,y_test))\n",
    "\n",
    "\n",
    "\n",
    "# model_json = model.to_json()\n",
    "# with open(\"emothionDetector.json\", 'w') as json_file:\n",
    "#     json_file.write(model_json)\n",
    "# model.save(\"emothionDetector.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Image is of fear\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "model predictoin is :  fear\n"
     ]
    }
   ],
   "source": [
    "json_file = open(\"emothionDetector.json\", 'r')\n",
    "model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(model_json)\n",
    "model.load_weights(\"emothionDetector.h5\")\n",
    "\n",
    "\n",
    "label = ['angry','disgust','fear','happy','neutral','sad','surprise']\n",
    "\n",
    "def ef(image):\n",
    "    img = load_img(image,color_mode='grayscale')\n",
    "    feature = np.array(img)\n",
    "    feature = feature.reshape(1,48,48,1)\n",
    "    return feature/255.0\n",
    "\n",
    "\n",
    "image = 'images/train/fear/49.jpg'\n",
    "print(\"Original Image is of fear\")\n",
    "\n",
    "\n",
    "img = ef(image)\n",
    "\n",
    "pred = model.predict(img)\n",
    "pred_label = label[pred.argmax()]\n",
    "print(\"model predictoin is : \", pred_label)\n",
    "\n",
    "\n",
    "\n",
    "# plt.imshow(img.reshape(48,48), cmap='gray')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
